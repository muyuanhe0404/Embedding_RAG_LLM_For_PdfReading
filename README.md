# GatsbyÂ QAÂ System

![license](https://img.shields.io/badge/license-MIT-blue.svg)Â Â ![madeÂ with](https://img.shields.io/badge/made%20with-Python%20%E2%9D%A4%EF%B8%8F-brightgreen)Â Â ![chatgpt](https://img.shields.io/badge/powered%20by-LLM-purple)

> **Ask anything about *Theâ€¯Greatâ€¯Gatsby* and get crisp, cited answers in seconds.**

A lightâ€‘weight Retrievalâ€‘Augmented Generation (RAG) demo that converts the novel PDF into an interactive flashâ€‘card experienceâ€”all on commodity hardware.

---

## âœ¨Â Features

* **5-8â€¯s latency** on a single CPU core
* Minimal **PythonÂ +Â FastAPI** backâ€‘end, **vanilla JS** frontâ€‘end (no heavy frameworks)
* Offline PDF ingestion â†’ FAISS indexâ€¦ only once
* OpenAI chat completion for final wording
* Responsive flashâ€‘card UI with animated skeleton loaders
* Oneâ€‘command local launch or dropâ€‘in Dockerfile

---

## ğŸ—ï¸Â SystemÂ Design

```mermaid
flowchart LR
    subgraph Offline
        A[PDF] --> B[preâ€‘processing]
        B --> C[FAISS index]
    end

    subgraph Runtime
        F[Frontâ€‘end] --> G[FastAPI]
        G --> H[retrieve]
        H --> I[reâ€‘rank]
        I --> J[(LLMÂ API)]
        J --> K[JSON answer]
        K --> F
    end

    C -. nearest passages .-> H
```

---

## ğŸš€Â Quickâ€‘start

```bash
# 1ï¸âƒ£Â Clone & install
$ git clone && cd independent
$ pip install -r requirements.txt

# 2ï¸âƒ£Â Set your OpenAI API key
$ export OPENAI_API_KEY="skâ€‘..."

# 3ï¸âƒ£Â Build the index (first run only)
$ python3 backend/in_p.py

# 4ï¸âƒ£Â Launch
$ cd independent/backend
$ uvicorn backend.main:app --port 8000 --reload
$ open http://localhost:8000 to see
```

---

## ğŸ—‚ï¸Â ProjectÂ layout

```
â”œâ”€ backend/
â”‚Â Â â”œâ”€ in_p.pyÂ Â Â Â Â Â Â Â Â Â Â Â Â # offline index builder
â”‚Â Â â”œâ”€ answer_rag.pyÂ Â Â Â Â Â Â # helper functions
â”‚Â Â â””â”€ main.pyÂ Â Â Â Â Â Â Â Â Â Â Â Â # FastAPI app (POST /ask)
â”œâ”€ frontend/
â”‚Â Â â”œâ”€ index.html
â”‚Â Â â””â”€ style.css
â”œâ”€ data/Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â # PDF, FAISS index, pickled chunks
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## ğŸ”§Â Configuration

| Variable | Default | Description |
|----------|---------|-------------|
| `OPENAI_API_KEY` | â€” | Your OpenAI secret key |
| `TOP_K` | `3` | Number of passages returned by FAISS |
| `MODEL_NAME` | `gpt-4o-mini` | Chat model for answer generation (can be changed)|

Adjust constants in `backend/answer_rag.py` to tune passage size, overlap, or temperature.

---

## ğŸ§ªÂ Testing

send a manual curl:

```bash
curl -X POST localhost:8000/ask -H "Content-Type: application/json" \
     -d '{"question":"What are the major themes of the novel?"}'
```

---

## ğŸ—ºï¸Â Roadmap

- [ ] Stream tokens to frontâ€‘end for instant feedback
- [ ] Multiâ€‘document support
- [ ] Darkâ€‘mode toggle
- [ ] Dynamic style variants

---

## ğŸ“œÂ License

MIT Â©â€¯2025 MuyuanÂ He

---

## ğŸ™Â Acknowledgments

* [pdfminer.six](https://github.com/pdfminer/pdfminer.six) for reliable PDF text extraction
* [Sentenceâ€‘Transformers](https://www.sbert.net/) and [FAISS](https://github.com/facebookresearch/faiss) for fast semantic search
* [OpenAI](https://platform.openai.com/) for the chat completion API
